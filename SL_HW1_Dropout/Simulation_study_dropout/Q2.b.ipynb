{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "'''Generate Feature Vector'''\n",
    "def generate_feature_set():\n",
    "    feature_set = pd.DataFrame(np.zeros((75, 100)))\n",
    "    for i in range(0,75):\n",
    "        feature_set.iloc[i,:] = np.random.uniform(1,100,100)\n",
    "    return feature_set\n",
    "\n",
    "'''Generate response'''\n",
    "def generate_response(mean):\n",
    "    return np.random.normal(mean * 100,10,75)\n",
    "\n",
    "'''Artificial Noise'''\n",
    "def add_noise(delta,f):\n",
    "    list_of_dataframes=[]\n",
    "    features_used = f.copy()\n",
    "    artificial_error=np.random.binomial(1,delta,features_used.shape[0]) / ((1-(delta)))\n",
    "    for i in range(features_used.shape[1]):\n",
    "        features_used.iloc[:,i]= artificial_error * features_used.iloc[:,i]\n",
    "    \n",
    "    return features_used\n",
    "\n",
    "'''Fit the model and calculate error'''\n",
    "def calculate_error(X,y):\n",
    "    reg = linear_model.LinearRegression(normalize= True,fit_intercept=True)\n",
    "    reg.fit(X,y)\n",
    "    preds=reg.predict(X)\n",
    "    \n",
    "    return np.mean(np.square(preds - y))\n",
    "\n",
    "''''''\n",
    "def delta_run(delta_vec,m,features,response):\n",
    "    df=pd.DataFrame(columns=['delta_values','values_of_m','errors'])\n",
    "    m_errors=[]\n",
    "    m_values=[]\n",
    "    delta_values=[]\n",
    "    \n",
    "    for delta in delta_vec:\n",
    "        for i in range(m):\n",
    "            m_errors.append(calculate_error(add_noise(delta,features).values,response))\n",
    "            m_values.append(i)\n",
    "            delta_values.append(delta)\n",
    "            \n",
    "    df.iloc[:,0]=delta_values\n",
    "    df.iloc[:,1]=m_values\n",
    "    df.iloc[:,2]=m_errors\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Generate Data Set'''\n",
    "feature_set =generate_feature_set()\n",
    "var = np.var(feature_set.var(axis=0))\n",
    "mean = np.mean(np.mean(feature_set))\n",
    "response = generate_response(mean,var)\n",
    "response = pd.DataFrame(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Split the Data Set in five Training and Test Ones'''\n",
    "train_set_1 = feature_set.iloc[:60,:]\n",
    "test_set_1 = feature_set.iloc[60:75]\n",
    "train_set_2 = feature_set.iloc[15:75,:]\n",
    "test_set_2 = feature_set.iloc[:15,:]\n",
    "train_set_3 = pd.concat([feature_set.iloc[:15,:],feature_set.iloc[30:,:]])\n",
    "test_set_3 = feature_set.iloc[15:30,:]\n",
    "train_set_4 = pd.concat([feature_set.iloc[:30,:],feature_set.iloc[45:,:]])\n",
    "test_set_4 = feature_set.iloc[30:45,:]\n",
    "train_set_5 = pd.concat([feature_set.iloc[:45,:],feature_set.iloc[60:,:]])\n",
    "test_set_5 = feature_set.iloc[45:60,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total average Error on five test Data Sets Using Ridge Regression is this\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    154.566244\n",
       "dtype: float64"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply Ridge Regression and Calculate MSE for all five Test Data Sets'''\n",
    "from sklearn.linear_model import Ridge \n",
    "ridge=Ridge(normalize=True)\n",
    "ridge.fit(train_set_1,response[:60])\n",
    "preds_ridge=ridge.predict(test_set_1)\n",
    "error_ridge1=np.mean(np.square(preds_ridge-response.iloc[60:75,:]))\n",
    "\n",
    "ridge.fit(train_set_2,response[15:75])\n",
    "preds_ridge=ridge.predict(test_set_2)\n",
    "error_ridge2=np.mean(np.square(preds_ridge-response.iloc[:15,:]))\n",
    "\n",
    "ridge.fit(train_set_3,pd.concat([response.iloc[:15,:],response.iloc[30:,:]]))\n",
    "preds_ridge=ridge.predict(test_set_3)\n",
    "error_ridge3=np.mean(np.square(preds_ridge-response.iloc[15:30,:]))\n",
    "\n",
    "ridge.fit(train_set_4,pd.concat([response.iloc[:30,:],response.iloc[45:,:]]))\n",
    "preds_ridge=ridge.predict(test_set_4)\n",
    "error_ridge4=np.mean(np.square(preds_ridge-response.iloc[30:45,:]))\n",
    "\n",
    "ridge.fit(train_set_5,pd.concat([response.iloc[:45,:],response.iloc[60:,:]]))\n",
    "preds_ridge=ridge.predict(test_set_5)\n",
    "error_ridge5=np.mean(np.square(preds_ridge-response.iloc[45:60,:]))\n",
    "\n",
    "tot_ridge = (error_ridge1+error_ridge2+error_ridge3+error_ridge4+error_ridge5)/5\n",
    "print ('Total average Error on five test Data Sets Using Ridge Regression is this')\n",
    "tot_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Average Error on five test Data Sets Using Lasso Regression is this\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111.47331260373883"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Apply Lasso Regression and Calculate MSE for all five Test Data Sets'''\n",
    "from sklearn.linear_model import Lasso \n",
    "lasso=Lasso(normalize=True)\n",
    "lasso.fit(train_set_1,response.iloc[:60,0])\n",
    "preds_lasso=lasso.predict(test_set_1)\n",
    "error_lasso1=np.mean(np.square(preds_lasso-response.iloc[60:75,0]))\n",
    "\n",
    "lasso.fit(train_set_2,response.iloc[15:75,0])\n",
    "preds_lasso=lasso.predict(test_set_2)\n",
    "error_lasso2=np.mean(np.square(preds_lasso-response.iloc[:15,0]))\n",
    "\n",
    "lasso.fit(train_set_3,pd.concat([response.iloc[:15,0],response.iloc[30:,0]]))\n",
    "preds_lasso=lasso.predict(test_set_3)\n",
    "error_lasso3=np.mean(np.square(preds_lasso-response.iloc[15:30,0]))\n",
    "\n",
    "lasso.fit(train_set_4,pd.concat([response.iloc[:30,0],response.iloc[45:,0]]))\n",
    "preds_lasso=lasso.predict(test_set_4)\n",
    "error_lasso4=np.mean(np.square(preds_lasso-response.iloc[30:45,0]))\n",
    "\n",
    "lasso.fit(train_set_5,pd.concat([response.iloc[:45,0],response.iloc[60:,0]]))\n",
    "preds_lasso=lasso.predict(test_set_5)\n",
    "error_lasso5=np.mean(np.square(preds_lasso-response.iloc[45:60,0]))\n",
    "\n",
    "tot_lasso = (error_lasso1+error_lasso2+error_lasso3+error_lasso4+error_lasso5)/5\n",
    "print ('Total Average Error on five test Data Sets Using Lasso Regression is this')\n",
    "tot_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Train 1 and Test 1'''\n",
    "delta_arr=np.arange(0,1,0.1)\n",
    "train_df_1=delta_run(delta_arr,100,train_set_1,response.iloc[:60,0])\n",
    "test_df_1=delta_run(delta_arr,100,test_set_1,response.iloc[60:75,0])\n",
    "'''Train 2 and Test 2'''\n",
    "delta_arr=np.arange(0,1,0.1)\n",
    "train_df_2=delta_run(delta_arr,100,train_set_2,response.iloc[15:75,0])\n",
    "test_df_2=delta_run(delta_arr,100,test_set_2,response.iloc[:15,0])\n",
    "'''Train 3 and Test 3'''\n",
    "delta_arr=np.arange(0,1,0.1)\n",
    "train_df_3=delta_run(delta_arr,100,train_set_3,pd.concat([response.iloc[:15,0],response.iloc[30:,0]]))\n",
    "test_df_3=delta_run(delta_arr,100,test_set_3,response.iloc[15:30,0])\n",
    "'''Train 4 and Test 4'''\n",
    "delta_arr=np.arange(0,1,0.1)\n",
    "train_df_4=delta_run(delta_arr,100,train_set_4,pd.concat([response.iloc[:30,0],response.iloc[45:,0]]))\n",
    "test_df_4=delta_run(delta_arr,100,test_set_4,response.iloc[30:45,0])\n",
    "'''Train 5 and Test 5'''\n",
    "delta_arr=np.arange(0,1,0.1)\n",
    "train_df_5=delta_run(delta_arr,100,train_set_5,pd.concat([response.iloc[:45,0],response.iloc[60:,0]]))\n",
    "test_df_5=delta_run(delta_arr,100,test_set_5,response.iloc[45:60,0])\n",
    "te_df=(test_df_1+test_df_2+test_df_3+test_df_4+test_df_5)/5\n",
    "min_error = te_df.loc[te_df.errors==np.min(te_df.errors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Comparison of Dropout,Ridge, and Lasso respectively\n",
      "34.11514475705463 0    154.566244\n",
      "dtype: float64 111.47331260373883\n",
      "Minimum Error Comparison of Drouput,Ridge and Lasso\n",
      "2.20581496681e-26\n",
      "55.871317395\n",
      "100.261688654\n",
      "Maximum Error Comparison of Drouput,Ridge and Lasso\n",
      "100.865400598\n",
      "178.681748823\n",
      "214.422645566\n"
     ]
    }
   ],
   "source": [
    "print ('Average Error Comparison of Dropout,Ridge, and Lasso respectively')\n",
    "print(np.mean(np.mean(te_df)),tot_ridge,tot_lasso) \n",
    "\n",
    "print ('Minimum Error Comparison of Drouput,Ridge and Lasso')\n",
    "print (te_df.loc[te_df.errors==np.min(te_df.errors)].iloc[0,2])\n",
    "print (np.min(np.array([error_lasso1,error_lasso2,error_lasso3,error_lasso4,error_lasso5])))\n",
    "print (np.min(np.array([error_ridge1,error_ridge2,error_ridge3,error_ridge4,error_ridge5])))\n",
    "\n",
    "print ('Maximum Error Comparison of Drouput,Ridge and Lasso')\n",
    "print (te_df.loc[te_df.errors==np.max(te_df.errors)].iloc[0,2])\n",
    "print (np.max(np.array([error_lasso1,error_lasso2,error_lasso3,error_lasso4,error_lasso5])))\n",
    "print (np.max(np.array([error_ridge1,error_ridge2,error_ridge3,error_ridge4,error_ridge5])))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
